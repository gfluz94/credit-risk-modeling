{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGD - Loss Given Default Model\n",
    "\n",
    "This notebook aims to come up with a general methodology for developing a model for estimating LGD - Loss Given Default.\n",
    "\n",
    "**LGD** represents the percentage of exposure that was lost after a borrower had defaulted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from credit_risk_modeling.cleaning import DatetimeConverter, NumericExtractor\n",
    "from credit_risk_modeling.feature_engineering import TimeSinceCalculator, OHECategoriesCreator\n",
    "from credit_risk_modeling.models import ZeroInflatedXGBoost\n",
    "from credit_risk_modeling.evaluation import get_regression_metrics, plot_regression_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data and select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = [\n",
    "    \"id\", \"member_id\", \"loan_amnt\", \"funded_amnt\", \"term\", \"int_rate\", \"installment\", \"grade\", \"emp_length\", \n",
    "    \"home_ownership\", \"annual_inc\", \"issue_d\", \"loan_status\", \"purpose\", \"addr_state\", \"dti\", \"delinq_2yrs\", \n",
    "    \"earliest_cr_line\", \"verification_status\", \"initial_list_status\", \"inq_last_6mths\", \"open_acc\", \"pub_rec\", \n",
    "    \"total_acc\", \"total_rev_hi_lim\", \"recoveries\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/loan_data.csv\")\n",
    "df = df.loc[:, selected_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean, Preprocess and Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"earliest_cr_line\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"earliest_cr_line\"] = df[\"earliest_cr_line\"].fillna(df[\"issue_d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_cols = [\"earliest_cr_line\", \"issue_d\"]\n",
    "datetime_format = \"%b-%y\"\n",
    "time_unit = \"month\"\n",
    "reference_date = datetime(2017, 12, 1)\n",
    "\n",
    "datetime_converter = DatetimeConverter(\n",
    "    field_names=datetime_cols,\n",
    "    datetime_format=datetime_format\n",
    ")\n",
    "df = datetime_converter.transform(df)\n",
    "\n",
    "for datetime_col in datetime_cols:\n",
    "    time_since_calculator = TimeSinceCalculator(\n",
    "        field_name=datetime_col, reference_date=reference_date, time_unit=time_unit, winsorize_max=True,\n",
    "    )\n",
    "    df = time_since_calculator.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_length_extractor = NumericExtractor(\n",
    "    field_name=\"emp_length\",\n",
    "    regex_extraction=r\"(.+)\\syears?\",\n",
    "    post_mapping={r\"10\\+\\s?\": str(10), r\"< 1\\s?\": str(0)},\n",
    ")\n",
    "df = emp_length_extractor.transform(df)\n",
    "\n",
    "emp_length_extractor = NumericExtractor(\n",
    "    field_name=\"term\",\n",
    "    regex_extraction=r\"(\\d+)\",\n",
    ")\n",
    "df = emp_length_extractor.transform(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for us to continue with the analysis, we just need to carry out two additional steps:\n",
    "\n",
    "* Define target variable\n",
    "\n",
    "When building LGD models, it is good practice to build models with data from borrowers that have had enough time to repay part of the remaining debt.\n",
    "\n",
    "Hence, we are going to take into account only borrowers that are written-off - which is indicated by `loan_status` equal to:\n",
    "\n",
    "* `Charged Off`\n",
    "\n",
    "* `Does not meet the credit policy. Status:Charged Off`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CATEGORIES = [\n",
    "    \"Charged Off\",\n",
    "    \"Does not meet the credit policy. Status:Charged Off\"\n",
    "]\n",
    "\n",
    "df = df[df[\"loan_status\"].isin(DEFAULT_CATEGORIES)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data provided, we know that:\n",
    "\n",
    "* `funded_amnt`: reflects the total amount that was lost at the moment the borrower defaulted;\n",
    "\n",
    "* `recoveries`: amount that has been recovered.\n",
    "\n",
    "Hence, LGD can be defined as:\n",
    "\n",
    "$LGD = \\frac{funded\\_amnt - recoveries}{funded\\_amnt} = 1 - recovery\\_rate$\n",
    "\n",
    "For this particular problem, we will focus on developing a model for the `recovery rate` and then, in order to compute LGD, it is as simple as substracting this rate from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43236.000000\n",
       "mean         0.060820\n",
       "std          0.089770\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.029466\n",
       "75%          0.114044\n",
       "max          1.220774\n",
       "Name: RR, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_VARIABLE = \"RR\"\n",
    "\n",
    "df[TARGET_VARIABLE] = df[\"recoveries\"] / df[\"funded_amnt\"]\n",
    "df[TARGET_VARIABLE].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that this value must be within the range [0, 1]. Hence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[TARGET_VARIABLE] = np.clip(df[TARGET_VARIABLE], a_min=0.0, a_max=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split our dataset into training and test, so that we avoid data leakage at all costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.20, random_state=99)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Features\n",
    "\n",
    "We will consider the categories we've come up with for the PD model, and take a look at how they are related to the target variable.\n",
    "\n",
    "* `grade`\n",
    "* `home_ownership`\n",
    "* `addr_state`\n",
    "* `verification_status`\n",
    "* `purpose`\n",
    "* `initial_list_status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = []\n",
    "features = []\n",
    "reference_categories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"grade\"\n",
    "final_categories = {\n",
    "    \"A\": [\"A\"],\n",
    "    \"B\": [\"B\"],\n",
    "    \"C\": [\"C\"],\n",
    "    \"D\": [\"D\"],\n",
    "    \"E\": [\"E\"],\n",
    "    \"F\": [\"F\"],\n",
    "    \"G\": [\"G\"],\n",
    "}\n",
    "\n",
    "grade_ohe = OHECategoriesCreator(field_name=variable, final_categories_dict=final_categories)\n",
    "df_train = grade_ohe.fit_transform(df_train)\n",
    "transformers.append(grade_ohe)\n",
    "features += [f\"{variable}_{cat}\" for cat in final_categories.keys()]\n",
    "reference_categories.append(f\"{variable}_\" + \"G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"home_ownership\"\n",
    "final_categories = {\n",
    "    \"NONE_OTHER_RENT_ANY\": [\"NONE\", \"OTHER\", \"RENT\", \"ANY\"],\n",
    "    \"MORTGAGE\": [\"MORTGAGE\"],\n",
    "    \"OWN\": [\"OWN\"],\n",
    "}\n",
    "\n",
    "grade_ohe = OHECategoriesCreator(field_name=variable, final_categories_dict=final_categories)\n",
    "df_train = grade_ohe.fit_transform(df_train)\n",
    "transformers.append(grade_ohe)\n",
    "features += [f\"{variable}_{cat}\" for cat in final_categories.keys()]\n",
    "reference_categories.append(f\"{variable}_\" + \"NONE_OTHER_RENT_ANY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"addr_state\"\n",
    "final_categories = {\n",
    "    \"NV_ND_ME_NE_IA\": [\"NV\", \"ND\", \"ME\", \"NE\", \"IA\"],\n",
    "    \"HI\": [\"HI\"],\n",
    "    \"FL\": [\"FL\"],\n",
    "    \"AL_OK_LA\": [\"AL\", \"OK\", \"LA\"],\n",
    "    \"NY\": [\"NY\"],\n",
    "    \"MO\": [\"MO\"],\n",
    "    \"MD_NJ_VA_NC_NM\": [\"NJ\", \"VA\", \"NC\", \"NM\", \"MD\"],\n",
    "    \"CA\": [\"CA\"],\n",
    "    \"TN_AZ_MI\": [\"TN\", \"AZ\", \"MI\"],\n",
    "    \"KY_RI_ID\": [\"KY\", \"RI\", \"ID\"],\n",
    "    \"PA_AR_OH_UT\": [\"PA\", \"AR\", \"OH\", \"UT\"],\n",
    "    \"MN_MA_SD\": [\"MN\", \"MA\", \"SD\"],\n",
    "    \"IN_OR_WA_GA\": [\"IN\", \"OR\", \"WA\", \"GA\"],\n",
    "    \"WI_DE\": [\"WI\", \"DE\"],\n",
    "    \"IL\": [\"IL\"],\n",
    "    \"TX\": [\"TX\"],\n",
    "    \"CT\": [\"CT\"],\n",
    "    \"WV_KS_CO_SC\": [\"WV\", \"KS\", \"CO\", \"SC\"],\n",
    "    \"MS_AK_MT_VT\": [\"MS\", \"AK\", \"MT\", \"VT\"],\n",
    "    \"NH_WY_DC\": [\"NH\", \"WY\", \"DC\"],   \n",
    "}\n",
    "\n",
    "grade_ohe = OHECategoriesCreator(field_name=variable, final_categories_dict=final_categories)\n",
    "df_train = grade_ohe.fit_transform(df_train)\n",
    "transformers.append(grade_ohe)\n",
    "features += [f\"{variable}_{cat}\" for cat in final_categories.keys()]\n",
    "reference_categories.append(f\"{variable}_\" + \"NV_ND_ME_NE_IA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"verification_status\"\n",
    "final_categories = {\n",
    "    v: [v] for v in df_train[variable].unique()\n",
    "}\n",
    "\n",
    "grade_ohe = OHECategoriesCreator(field_name=variable, final_categories_dict=final_categories)\n",
    "df_train = grade_ohe.fit_transform(df_train)\n",
    "transformers.append(grade_ohe)\n",
    "features += [f\"{variable}_{cat}\" for cat in final_categories.keys()]\n",
    "reference_categories.append(f\"{variable}_\" + \"Verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"purpose\"\n",
    "final_categories = {\n",
    "    \"car\": [\"car\"],\n",
    "    \"credit_card\": [\"credit_card\"],\n",
    "    \"major_purchase_home_improvement\": [\"major_purchase\", \"home_improvement\"],\n",
    "    \"debt_consolidation\": [\"debt_consolidation\"],\n",
    "    \"vacation_wedding\": [\"vacation\", \"wedding\"],\n",
    "    \"medical\": ['medical'],\n",
    "    \"other\": [\"other\"],\n",
    "    \"renewable_energy_house_moving\": [\"renewable_energy\", \"house\", \"moving\"],\n",
    "    \"educational_small_business\": [\"small_business\", \"educational\"],\n",
    "}\n",
    "\n",
    "grade_ohe = OHECategoriesCreator(field_name=variable, final_categories_dict=final_categories)\n",
    "df_train = grade_ohe.fit_transform(df_train)\n",
    "transformers.append(grade_ohe)\n",
    "features += [f\"{variable}_{cat}\" for cat in final_categories.keys()]\n",
    "reference_categories.append(f\"{variable}_\" + \"educational_small_business\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"initial_list_status\"\n",
    "final_categories = {\n",
    "    v: [v] for v in df_train[variable].unique()\n",
    "}\n",
    "\n",
    "grade_ohe = OHECategoriesCreator(field_name=variable, final_categories_dict=final_categories)\n",
    "df_train = grade_ohe.fit_transform(df_train)\n",
    "transformers.append(grade_ohe)\n",
    "features += [f\"{variable}_{cat}\" for cat in final_categories.keys()]\n",
    "reference_categories.append(f\"{variable}_\" + \"f\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric Features\n",
    "\n",
    "Since we are developing a regression model, which is not required to be either explainable or interpretable by expternal regulator, there is no need for binning numeric variables. Thus, we can proceed straight to EDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".credit-risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c5f5974d33210c1c5788d4128ca30f0fb4f95cfecbcad01169cd6bc1e53cbc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
